{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Runable 协议"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>|\n",
      "|嗯|，|用户|问|“|天空|是什么|颜色|”。|这个问题|挺|常见的|，|可能|在|广告|、|设计|或者|日常|生活中|经常|遇到|。|首先|，|我要|理解|用户|的需求|。|他们|可能|想|了解|天空|的颜色|如何|影响|整体|视觉|效果|，|或者是|用于|某种|创意|项目|。\n",
      "\n",
      "|我|应该|考虑|不同|颜色|的|天空|在|不同|文化|中的|表现|，|因为|很多|文化|对|颜色|都有|特别|的看法|和|习惯|。|比如|，在|一些|传统|艺术|作品|中|，|天空|被|描绘|成|紫色|或者|翠|绿|的|，|而|有些人|则|更|喜欢|鲜艳|的|红色|或|橙|色|。\n",
      "\n",
      "|另外|，|我也|要考虑|用户|是否|知道|天空|的颜色|会影响|整体|的感觉|。|如果|他们|是在|做|广告|，|可能会|强调|使用|柔和|的颜色|以|营造|舒适|的感觉|；|如果是|摄影|，|可能|需要|考虑|色彩|搭配|来|突出|某个|主题|。\n",
      "\n",
      "|我还|应该|想到|，|天空|的颜色|不仅仅|是一个|简单的|视觉|现象|，|它|也|反映了|文化和|历史|背景|。|不同的|文化|对|天空|的|描绘|和|定义|有|不同|理解|，|这点|在|回答|中|可以|提到|。\n",
      "\n",
      "|最后|，|用户|可能|想知道|是否有|具体的|科学|解释|，|或者|天空|颜色|的变化|如何|随|时间和|地点|变化|。|考虑到|这些|方面|，|我|可以在|回答|中|简|要|提及|一些|相关|知识|，|而|避免|过于|复杂|。\n",
      "|</think>|\n",
      "\n",
      "|天空|的颜色|是一个|广泛|且|复杂|的话题|，|因为它|受|多种|因素|的影响|，|包括|历史|、|文化|、|自然|现象|以及|人类|的|视觉|感知|。|以下|是一|些|常见的|背景|和|色彩|描述|：\n",
      "\n",
      "|1|.| **|传统|与|宗教|信仰|**|：|许多|地方|的|天空|颜色|与|宗教|或|传统|信仰|有关|：\n",
      "|  | -| 在|一些|文化|中|，|天空|可能|被|描绘|为|紫色|、|翠|绿|或者|深|红|的颜色|。\n",
      "|  | -| |佛教|教|义|中有|不同|颜色|的|天|光|，|例如|“|无|畏|”|（|白|）、|“|如|来|”|（|黄|）|等|。\n",
      "\n",
      "|2|.| **|艺术|与|设计|**|：|在|某些|创意|作品|中|，|天空|可能会|被|描绘|成|柔和|而|纯净|的|色调|：\n",
      "|  | -| 蓝|色|、|紫色|或|绿色|的|天空|常常|被认为是|温柔|而|宁静|的|，|常|用于|广告|和|宣传|材料|。\n",
      "|  | -| |一些|艺术家|喜欢|将|天空|描绘|得|更为|鲜艳|或|明亮|。\n",
      "\n",
      "|3|.| **|自然|现象|**|：|在|自然|环境中|，|天空|的颜色|也|受到|光照|和| atmospheric|条件|的影响|：\n",
      "|  | -| 高|noon|时刻|时|，|天空|通常是|乌|云|密|布|，|颜色|较|暗|淡|。\n",
      "|  | -| 在|清晨|或|黄昏|时|分|，|天空|可能|呈现出|更|明亮|、|柔和|的|色调|。\n",
      "\n",
      "|4|.| **|视觉|与|感觉|**|：|人类|对|颜色|的|感知|和|反应|会|根据|环境|的不同|而|变化|。|例如|：\n",
      "|  | -| 暗|色|的|天空|可能|被认为|宁静|或|干燥|。\n",
      "|  | -| 高|光|或|强烈的|色彩|可能|使|整个|画面|显得|热情|或者|刺|眼|。\n",
      "\n",
      "|5|.| **|科学|视角|**|：|在|科学|领域|，|天空|的颜色|与|大气|中的|成分|有关|（|如|水|蒸|气|、|氧气|和|二氧化碳|）|：\n",
      "|  | -| 空|气|中的|水|蒸|气|会|生成|云|雾|，|颜色|从|蓝|到|深|绿|再到|红色|。\n",
      "|  | -| 大|气|中的|氧气|浓度|较高|时|，|天空|通常|为|浅|色调|。\n",
      "\n",
      "|总结|来说|，|天空|的颜色|是一个|多|方面的|主题|，|主要|受到|历史|、|文化和|自然|因素|的影响|。|不同的|文化|中|对|天空|的|描绘|可能|因|季节|和|时间|而|有所不同|，|但|核心|在于|如何|将|这|丰富的|色彩|体验|传递|给|观众|或|读者|。||\n",
      " ['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'capitalize', 'casefold', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'format_map', 'index', 'isalnum', 'isalpha', 'isascii', 'isdecimal', 'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'removeprefix', 'removesuffix', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill']\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = OllamaLLM(model=\"deepseek-r1:1.5b\", base_url=\"http://localhost:11434\")\n",
    "\n",
    "chunks = []\n",
    "\n",
    "for chunk in model.stream(\"天空是什么颜色\"):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk, end=\"|\", flush=True)\n",
    "    # print(chunk.content, end=\"|\", flush=True)\n",
    "    \n",
    "print(\"\\n\",dir(chunk)) # chunk 是一个字符串类型，并不像OpenAI的ChatOpenAI那样有content属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('问', '”。', '可能')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[5],chunks[10],chunks[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 异步调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "import asyncio\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts.chat import HumanMessagePromptTemplate\n",
    "\n",
    "# ChatPromptTemplate.from_messages()期望传入的格式极为严格，\n",
    "# 每个message必须包含role和content属性，并且content属性必须是一个字符串。\n",
    "# 如果传入的message不满足这些要求，ChatPromptTemplate.from_messages()会抛出一个ValueError异常。\n",
    "\n",
    "\n",
    "# 修改这部分，使用HumanMessagePromptTemplate创建符合格式的消息\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    HumanMessagePromptTemplate.from_template(\"给我讲一个关于{topic}的故事\")\n",
    "])\n",
    "\n",
    "model = OllamaLLM(model=\"deepseek-r1:1.5b\", base_url=\"http://localhost:11434\")\n",
    "# parser = StrOutputParser()\n",
    "# chain = prompt | model | parser\n",
    "chain = prompt | model\n",
    "\n",
    "async def async_stream():\n",
    "    async for chunk in chain.stream({\"topic\":\"天空\"}):\n",
    "        print(chunk, end=\"|\", flush=True)\n",
    "\n",
    "# asyncio.run(async_stream()) # chain.stream({\"topic\":\"天空\"}) 返回的是一个普通的生成器对象，\n",
    "# 而不是一个实现了异步迭代协议（即具有 __aiter__ 和 __anext__ 方法）的异步可迭代对象\n",
    "\n",
    "# 因此，在调用 asyncio.run() 时，Python 会尝试将生成器对象转换为异步可迭代对象，\n",
    "# 但由于生成器对象本身并不实现异步迭代协议，因此会引发 TypeError 异常。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>|\n",
      "|嗯|，|用户|让我|给|一个|关于|天空|的故事|。|首先|，|我|得|想想|什么|故事|适合|天空|？|可能|需要|一个|有趣|且|有|深度|的|设定|。|毕竟|，|天空|是|天|体|的一种|，|有很多|科学|和|艺术|上的|内容|。\n",
      "\n",
      "|我觉得|古|希腊|是一个|不错|的选择|，|那里|有很多|涉及|天空|的|神话|和|哲学|故事|。|比如|，|赫|拉|克|勒|斯|和|西|西|弗|斯|的故事|，|这些|都|与|永恒|和|循环|有关|。|还有|雅|典|娜|，|她|被|囚|禁|在|海|神| cre|on| 的|牢|笼|中|，|这|涉及到|命运|、|生命|和|永恒|的主题|。\n",
      "\n",
      "|接下来|，|用户|可能|希望|看到|一个|既有|历史|深度|又|不失|现代|感|的故事|。|所以|，|我|需要|将|古|希腊|神话|中的|元素|融入|到|现代|的|场景|中|去|。|比如|，|把|海|神| cre|on| 换|成|一个|普通人|，|或者|把|故事|的时间|线|调整|为|更|贴近|现实|的生活|。\n",
      "\n",
      "|再|想想|，|天空|在|故事|中的|角色|可以|如何|发展|。|比如|，|西|西|弗|斯|被|太阳|驱|逐| upwards|，|而不是|被|吸|进去|。|这样|既|有趣|又|符合|古|希腊|神话|的|风格|。|同时|，|海|神| cre|on| 的|命运|也可以|变成|普通|人的|命运|，|增加|故事|的真实|感|和|情感|共鸣|。\n",
      "\n",
      "|然后|，|我|得|考虑|故事|的|结构|。|开头|可以|介绍|一个|普通人|与|天空|互动|的情|节|，|中间|引|出|西|西|弗|斯|的故事|，|最后|揭示|永恒|的主题|。|这样|结构|清晰|，|逻辑|连|贯|。\n",
      "\n",
      "|另外|，|用户|可能|还|希望|了解|关于|天空|的一些|科学|知识|，|比如|恒|星|、|地球|自|转|等|，|但|不要|过于|晦|涩|。|可以在|故事|中|自然|地|融入|这些|知识点|，|让|读者|有|更深|的理解|。\n",
      "\n",
      "|最后|，|结尾|部分|可以|点|出|天空|作为|永恒|存在|的重要性|，|或者|展望|未来|，|为|故事|留下|悬念|或|启发|。|这样|不仅|满足|了|用户|的需求|，|还能|引发|进一步|的|思考|和|讨论|。\n",
      "|</think>|\n",
      "\n",
      "|##| 天|空|里的|舞|者|\n",
      "\n",
      "|人类|文明|中最|璀璨|的|天|体|是|太阳|，|它是|宇宙|中的|恒|星|，|也是|时间|的|循环|。|每年|春天|，|当|天空|中|飘|落|雪花|时|，|西|西|弗|斯|会|被|太阳|带|向|更高的|地方|。\n",
      "\n",
      "|他|穿着|一件|淡|紫色|的|长|袍|，|提|着|装|满|各种|珍|宝|的|大|包|，|缓缓|迈|上|山|巅|。|清晨|的|阳光|洒|在|他的|白|发|间|，|让他|显得|格外|庄|重|。|远处|传来|几|声|鸟|鸣|，|像是|有|无数|只|小鸟|在|跳跃|，|又|像是|无数|个|永恒|的存在|正在|等待|下一个|机会|。\n",
      "\n",
      "|他|停下来|休息|，|闭|着眼|睛|，|任|由|呼吸|吞噬|一切|。|突然|，|一道|微|弱|的|光|从|天|而|降|，|将|他的|长|袍|拉|扯|成|一条|细|长|的|绳|索|。|这|股|力量|让他|倒|下|，|跌|进|了一|条|蜿|蜒|的小|河|里|。\n",
      "\n",
      "|天空|在|下方|漂|浮|着|无数|颗|闪烁|的|星辰|，|像是|无数|双|永远|等待|着|的眼睛|。|阳光|穿过|云|层|，在|地上|投|下|一道|长长的|光|带|，|仿佛|是一|道|永恒|的|纽带|。\n",
      "\n",
      "|西|西|弗|斯|走到|河边|，|看着|那些|星辰|不|时|地|移动|。|夜|色|渐|深|，|天|上的|星|象|开始|重组|，|就像|时间|在|流动|，|带着|我们|前行|的脚步|永|不停|息|。|他|站|起身|来|，|朝着|天空|喊|道|：\n",
      "\n",
      "|\"|让我|看看|，|这些|永恒|的|星辰|会|住|在哪里|？|\"\n",
      "\n",
      "|阳光|穿透|云|层|，在|空中|划|出|一道|优|美的|弧|线|，|如同|无数|个|舞|者|正在|跳|动|永恒|的|节|拍|。||"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts.chat import HumanMessagePromptTemplate\n",
    "\n",
    "\n",
    "# 包装生成器为异步可迭代对象的类\n",
    "class AsyncGeneratorWrapper:\n",
    "    def __init__(self, gen):\n",
    "        # 初始化时传入一个生成器对象\n",
    "        self.gen = gen\n",
    "\n",
    "    def __aiter__(self):\n",
    "        # 使该类的实例成为异步可迭代对象\n",
    "        return self\n",
    "\n",
    "    async def __anext__(self):\n",
    "        try:\n",
    "            # 使用 asyncio.to_thread 避免阻塞事件循环，将同步的 next 调用放到单独线程执行\n",
    "            return await asyncio.to_thread(next, self.gen)\n",
    "        except StopIteration:\n",
    "            # 当生成器耗尽时，抛出异步迭代结束的异常\n",
    "            raise StopAsyncIteration\n",
    "        except Exception as e:\n",
    "            # 捕获并打印其他可能出现的异常\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            # 出现异常时也结束异步迭代\n",
    "            raise StopAsyncIteration\n",
    "\n",
    "\n",
    "# 创建一个聊天提示模板，接收一个 topic 参数，用于生成用户的提问消息\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    HumanMessagePromptTemplate.from_template(\"给我讲一个关于{topic}的故事\")\n",
    "])\n",
    "\n",
    "# 初始化 Ollama 语言模型，指定模型名称和服务地址\n",
    "model = OllamaLLM(model=\"deepseek-r1:1.5b\", base_url=\"http://localhost:11434\")\n",
    "# 初始化输出解析器，将模型的输出解析为字符串\n",
    "parser = StrOutputParser()\n",
    "# 构建一个链式处理流程，先使用提示模板处理输入，再经过模型生成输出，最后用解析器解析输出\n",
    "chain = prompt | model | parser\n",
    "\n",
    "\n",
    "async def async_stream():\n",
    "    # 调用链式处理流程的 stream 方法，传入 topic 参数，得到一个生成器\n",
    "    gen = chain.stream({\"topic\": \"天空\"})\n",
    "    # 将生成器包装成异步可迭代对象\n",
    "    async_gen = AsyncGeneratorWrapper(gen)\n",
    "    # 异步迭代生成器，逐块输出内容\n",
    "    async for chunk in async_gen:\n",
    "        # 打印每一块内容，以 | 作为分隔符，并立即刷新输出缓冲区\n",
    "        print(chunk, end=\"|\", flush=True)\n",
    "\n",
    "\n",
    "# 根据环境决定是否使用 asyncio.run\n",
    "try:\n",
    "    # 获取当前正在运行的事件循环\n",
    "    loop = asyncio.get_running_loop()\n",
    "    if loop.is_running():\n",
    "        # 如果事件循环正在运行，创建一个任务来运行异步函数\n",
    "        loop.create_task(async_stream())\n",
    "    else:\n",
    "        # 如果事件循环未运行，使用 asyncio.run 来运行异步函数\n",
    "        asyncio.run(async_stream())\n",
    "except RuntimeError:\n",
    "    # 如果获取运行的事件循环时出现错误，使用 asyncio.run 来运行异步函数\n",
    "    asyncio.run(async_stream())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'countries': {}}\n",
      "{'countries': {'france': {}}}\n",
      "{'countries': {'france': {'name': ''}}}\n",
      "{'countries': {'france': {'name': 'France'}}}\n",
      "{'countries': {'france': {'name': 'France', 'population': 6}}}\n",
      "{'countries': {'france': {'name': 'France', 'population': 67}}}\n",
      "{'countries': {'france': {'name': 'France', 'population': 670}}}\n",
      "{'countries': {'france': {'name': 'France', 'population': 6700}}}\n",
      "{'countries': {'france': {'name': 'France', 'population': 67002}}}\n",
      "{'countries': {'france': {'name': 'France', 'population': 670024}}}\n",
      "{'countries': {'france': {'name': 'France', 'population': 6700246}}}\n",
      "{'countries': {}}\n",
      "{'countries': {'france': {'name': 'France', 'population': 6700246}}}\n",
      "{'countries': {}}\n",
      "{'countries': {'france': {'name': 'France', 'population': 6700246}}}\n",
      "{'countries': {}}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "# 从 langchain_ollama 库导入 OllamaLLM 类，用于调用 Ollama 模型\n",
    "from langchain_ollama import OllamaLLM\n",
    "# 从 langchain_core.output_parsers 库导入 JsonOutputParser 类，用于将模型输出解析为 JSON 格式\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# 初始化 Ollama 语言模型，指定模型名称为 deepseek-r1:1.5b，模型服务的基础 URL 为 http://localhost:11434\n",
    "model = OllamaLLM(model=\"deepseek-r1:1.5b\", base_url=\"http://localhost:11434\")\n",
    "# 创建一个链式调用，先使用模型进行推理，然后使用 JsonOutputParser 将输出解析为 JSON 格式\n",
    "chain = (model | JsonOutputParser())\n",
    "\n",
    "# 定义一个类，用于将同步生成器包装成异步生成器\n",
    "class AsyncGeneratorWrapper:\n",
    "    def __init__(self, gen):\n",
    "        # 初始化时接收一个同步生成器对象\n",
    "        self.gen = gen\n",
    "\n",
    "    def __aiter__(self):\n",
    "        # 使该类的实例成为异步可迭代对象\n",
    "        return self\n",
    "\n",
    "    async def __anext__(self):\n",
    "        try:\n",
    "            # 使用 asyncio.to_thread 将同步的 next 调用放到单独的线程中执行，避免阻塞事件循环\n",
    "            return await asyncio.to_thread(next, self.gen)\n",
    "        except StopIteration:\n",
    "            # 当同步生成器耗尽时，抛出异步迭代结束的异常\n",
    "            raise StopAsyncIteration\n",
    "\n",
    "# 定义一个异步函数，用于流式处理模型的输出\n",
    "async def async_stream():\n",
    "    # 调用 chain 的 stream 方法，传入请求内容，得到一个同步生成器，该请求要求以特定 JSON 格式输出国家及人口列表\n",
    "    gen = chain.stream(\n",
    "        \"以JSON 格式输出法国、西班牙和日本的国家及人口列表。\"\n",
    "        '使用一个带有“countries”外部键的字典，其中包含国家列表。'\n",
    "        '每个国家都应该有键“name”和“population”。'\n",
    "    )\n",
    "    # 将同步生成器包装成异步生成器\n",
    "    async_gen = AsyncGeneratorWrapper(gen)\n",
    "    # 异步迭代异步生成器，逐块获取模型输出\n",
    "    async for text in async_gen:\n",
    "        # 打印每一块输出，并立即刷新输出缓冲区\n",
    "        print(text, flush=True)\n",
    "\n",
    "try:\n",
    "    # 获取当前正在运行的事件循环\n",
    "    loop = asyncio.get_running_loop()\n",
    "    if loop.is_running():\n",
    "        # 如果事件循环正在运行，创建一个任务来运行异步函数\n",
    "        loop.create_task(async_stream())\n",
    "    else:\n",
    "        # 如果事件循环未运行，使用 asyncio.run 来运行异步函数\n",
    "        asyncio.run(async_stream())\n",
    "except RuntimeError:\n",
    "    # 如果获取运行的事件循环时出现错误，使用 asyncio.run 来运行异步函数\n",
    "    asyncio.run(async_stream())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xhd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
