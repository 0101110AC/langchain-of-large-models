{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Runable 协议"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>|\n",
      "\n",
      "|</think>|\n",
      "\n",
      "|天空|的颜色|因|人|而|异|，|既|然是|“|空|”的|话|，|自然|不会|有任何|色彩|。|然而|，在|不同的|文化|中|，|我们|可能会|赋予|天空|独特的|“|颜色|”|以|象征|意义|。\n",
      "\n",
      "|-| **|东方|文化|**|：|在|东方|文化|中|，|天空|是|柔和|的|橙|红色|、|黄色|或|橘|色|，|象征|着|希望|和|繁荣|。\n",
      "|-| **|西方|文化|**|：|在|西方|文化|中|，|天空|通常|被认为|是最|亮|的|，|有时|呈现出|蓝色|、|紫色|或|金色|，|象征|着|光明|和|高|洁|。\n",
      "\n",
      "|每个|地方|都有|独特的|文化和|自然|选择|赋予|天空|不同的|“|颜色|”，|但|这些|颜色|本质上|都是|空|的|。||\n",
      " ['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'capitalize', 'casefold', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'format_map', 'index', 'isalnum', 'isalpha', 'isascii', 'isdecimal', 'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'removeprefix', 'removesuffix', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill']\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = OllamaLLM(model=\"deepseek-r1:1.5b\", base_url=\"http://localhost:11434\")\n",
    "\n",
    "chunks = []\n",
    "\n",
    "for chunk in model.stream(\"天空是什么颜色\"):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk, end=\"|\", flush=True)\n",
    "    # print(chunk.content, end=\"|\", flush=True)\n",
    "    \n",
    "print(\"\\n\",dir(chunk)) # chunk 是一个字符串类型，并不像OpenAI的ChatOpenAI那样有content属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('的颜色', '，', '”的')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[5],chunks[10],chunks[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 异步调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "import asyncio\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts.chat import HumanMessagePromptTemplate\n",
    "\n",
    "# ChatPromptTemplate.from_messages()期望传入的格式极为严格，\n",
    "# 每个message必须包含role和content属性，并且content属性必须是一个字符串。\n",
    "# 如果传入的message不满足这些要求，ChatPromptTemplate.from_messages()会抛出一个ValueError异常。\n",
    "\n",
    "\n",
    "# 修改这部分，使用HumanMessagePromptTemplate创建符合格式的消息\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    HumanMessagePromptTemplate.from_template(\"给我讲一个关于{topic}的故事\")\n",
    "])\n",
    "\n",
    "model = OllamaLLM(model=\"deepseek-r1:1.5b\", base_url=\"http://localhost:11434\")\n",
    "# parser = StrOutputParser()\n",
    "# chain = prompt | model | parser\n",
    "chain = prompt | model\n",
    "\n",
    "async def async_stream():\n",
    "    async for chunk in chain.stream({\"topic\":\"天空\"}):\n",
    "        print(chunk, end=\"|\", flush=True)\n",
    "\n",
    "# asyncio.run(async_stream()) # chain.stream({\"topic\":\"天空\"}) 返回的是一个普通的生成器对象，\n",
    "# 而不是一个实现了异步迭代协议（即具有 __aiter__ 和 __anext__ 方法）的异步可迭代对象\n",
    "\n",
    "# 因此，在调用 asyncio.run() 时，Python 会尝试将生成器对象转换为异步可迭代对象，\n",
    "# 但由于生成器对象本身并不实现异步迭代协议，因此会引发 TypeError 异常。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>|\n",
      "|嗯|，|用户|让我|讲|一个|关于|天空|的故事|。|首先|，|我|得|想想|这个|故事|应该|是什么|样的|。|可能|从|自然|景象|开始|，|然后|引|出|一些|象征|意义|或者|寓意|。|天空|通常|象征|着|自由|、|广阔|和|神秘|，|所以|故事|里|可以|突出|这些|元素|。\n",
      "\n",
      "|用户|的需求|是|讲|一个|简单|的故事|，|所以我|需要|选择|一个|不|复杂|但|又有|深度|的主题|。|或许|可以从|日常生活|中的|某个|瞬间|切入|，|比如|下雨|天|，|这样|容易|引起|共鸣|。|同时|，|加入|一些|细节|会让|故事|更|生动|。\n",
      "\n",
      "|接下来|，|考虑|主角|的选择|。|可能|是一个|普通人|，|比如|一个|喜欢|自然|的朋友|，|或者|有|特殊|能力|的人|。|假设|是|朋友|的话|，|可以|描述|她|因为|下雨|而|发现|的|天空|之|谜|，|这样|既|真实|又|容易|展开|情节|。\n",
      "\n",
      "|然后|，|结构|上|应该|有一个|引|人|入|胜|的|开头|，|中间|的情|节|发展|，|最后|有一个|感|人的|结尾|。|引|言|部分|可以通过|一个小|插|曲|引入|，|比如|她|从|不|关|窗户|开始|，|这样|自然|地|引|出|她的|探索|之旅|。\n",
      "\n",
      "|在|描写|场景|时|，|要|细致|刻画|环境|，|比如|雨|后的|天空|、|树叶|上的|露|珠|、|泥土|的颜色|等|细节|，|让|读者|有|身|临|其|境|的感觉|。|同时|，|加入|一些|象征|性的|元素|，|比如|露|珠|代表|希望|，|沙|粒|象征|寂静|和|黑暗|中的|光明|，|这样|故事|更有|深度|。\n",
      "\n",
      "|最后|，|结尾|部分|需要|给人|留下|深刻|的印象|，|可能|是一个|温暖|的|感悟|或者|令人|反思|的主题|。|比如|她|发现|天空|的秘密|，|学会了|在|困难|时|保持|乐观|，|这样的|结局|既|感人|又|有力|。\n",
      "\n",
      "|总的来说|，|我|需要|构建|一个|简单|但|富有|层次|感|的故事|，|通过|自然|元素|和|隐|喻|，|传达|出|关于|天空|和|内心的|和谐|。|这样|不仅|满足|了|用户|的需求|，|还能|给|读者|带来|启发|和|情感|上的|共鸣|。\n",
      "|</think>|\n",
      "\n",
      "|##| |《|雨|后的|秘密|》|\n",
      "\n",
      "|我|从|不|关|窗户|。\n",
      "\n",
      "|这是|我|从小|养成|的习惯|。|从|一|岁|起|，|我就|习惯|让|阳光|照|进来|——|有时候|是|阳光|，|有时候|是|雨水|，|或者|甚至是|清|风|轻|语|。\n",
      "\n",
      "|记得|那天|放学|后|，|天空|像|被|风吹|散|了一|片|野|草|，在|暮|色|中|显得|格外|陌生|。|我|躲在|窗|边|，|看着|天|上的|云|彩|翻|滚|着|，|那|不是|一般的|美丽|。\n",
      "\n",
      "|\"|你|总是|这样|，|就像|春天|的|溪|流|一样|温柔|地|奔|涌|。|\"|妈妈|站在|窗外|，|轻轻|拍|了|拍|我的|肩膀|。\n",
      "\n",
      "|我的|心|突然|不受|控制|地|泛| up|,| 气|压|急剧|上升|。\n",
      "\n",
      "|雨|丝|打|在|地板|上|,|发出|\"|噼|里|啪|啦|\"|的|声响|。|我|抬头|望|向|天|际|,| |一道|细|长|的|云|彩|正在|缓缓|升起|。|那|是一个|小小的|云|层|,| 像|是一|只|小|猫|轻轻|摇|晃|着|脑袋|,| 看|起来|比|平时|低|了许多|。\n",
      "\n",
      "|突然|间|,| 天|空|亮|了起来|。|第一|片|云|彩|在|阳光|下|泛|着|微|光|,| 形|成了|一个小|太阳|。|然后|就|接着|出现|,| |一层|接着|一层|,| 直|到|天|边|露出|一个|半|透明|的|圆|盘|。\n",
      "\n",
      "|我|站在|窗|前|,| 快|步|走|过去|。|雨|丝|打|湿|了|玻璃|,| 就|在我|犹豫|要不要|关|上|时|,| |一道|清晰|的|光线|从|缝隙|中|斜|射|进来|。\n",
      "\n",
      "|\"|这是|云|,| 是|太阳|吗|？|\"\n",
      "\n",
      "|我的|脸上|泛|起|红|晕|。|这个|动作|太|简单|了|,| 我|觉得|这|道|光|应该|很快|就会|消失|得|无|影|无|踪|。\n",
      "\n",
      "|直到|天|边|又|开始|出现|暗|纹|,| |一个|完整的|太阳|逐渐|显现|出来|。||"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from langchain_ollama import OllamaLLM\n",
    "import asyncio\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts.chat import HumanMessagePromptTemplate\n",
    "\n",
    "\n",
    "# 包装生成器为异步可迭代对象的类\n",
    "class AsyncGeneratorWrapper:\n",
    "    def __init__(self, gen):\n",
    "        self.gen = gen\n",
    "\n",
    "    def __aiter__(self):\n",
    "        return self\n",
    "\n",
    "    async def __anext__(self):\n",
    "        try:\n",
    "            return next(self.gen)\n",
    "        except StopIteration:\n",
    "            raise StopAsyncIteration\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    HumanMessagePromptTemplate.from_template(\"给我讲一个关于{topic}的故事\")\n",
    "])\n",
    "\n",
    "model = OllamaLLM(model=\"deepseek-r1:1.5b\", base_url=\"http://localhost:11434\")\n",
    "parser = StrOutputParser()\n",
    "chain = prompt | model | parser\n",
    "\n",
    "\n",
    "async def async_stream():\n",
    "    gen = chain.stream({\"topic\": \"天空\"})\n",
    "    async_gen = AsyncGeneratorWrapper(gen)\n",
    "    async for chunk in async_gen:\n",
    "        print(chunk, end=\"|\", flush=True)\n",
    "\n",
    "\n",
    "asyncio.run(async_stream())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xhd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
